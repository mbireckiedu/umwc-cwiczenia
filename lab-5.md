---

# ğŸ§ª AML Lab 02 â€“ Dataset, trening modelu i rejestracja w Azure Machine Learning



---

## ğŸ“š Spis treÅ›ci


1. [KROK 0 â€“ Klon repozytorium (GitHub + PAT)](#k0)
2. [KROK 1 â€“ Odtworzenie AML Workspace z Terraform](#k1)
3. [KROK 2 â€“ Konfiguracja Azure ML CLI v2 i Compute Cluster](#k2)
4. [KROK 3 â€“ Struktura katalogu `aml-lab-02`](#k3)
5. [KROK 4 â€“ Job do generowania danych (`data_prep.py` + `data_job.yml`)](#k4)
6. [KROK 5 â€“ Pobranie danych i rejestracja Data Asset](#k5)
7. [KROK 6 â€“ Kod treningowy modelu (`train.py`)](#k6)
8. [KROK 7 â€“ Training job (`training_job.yml`)](#k7)
9. [KROK 8 â€“ Rejestracja modelu](#k8)
10. [KROK 9 â€“ SprzÄ…tanie zasobÃ³w](#k9)
11. [KROK 10 â€“ Dodanie plikÃ³w do repozytorium](#k10)
12. [Dokumentacja](#docs)

---



## ğŸ” KROK 0 â€“ Klon repozytorium (GitHub + PAT) <a id="k0"></a>

Kroki 0 i 1, sÄ… dokÅ‚adnie takie jak w poprzednim Ä‡wiczeniu. JeÅ›li masz zapisany swÃ³j Token, moÅ¼esz przejÅ›c od razu do klonowania repozytorium.

Pracujemy w **Azure Cloud Shell (Bash)**: [https://shell.azure.com](https://shell.azure.com)

### 0.1 Konfiguracja Gita

```bash
git config --global user.name  "ImiÄ™ Nazwisko"
git config --global user.email "twoj.mail@dsw.edu.pl"
git config --global credential.helper 'cache --timeout=3600'
```

### 0.2 Personal Access Token (PAT) w GitHub

1. GitHub â†’ **Settings â†’ Developer settings â†’ Personal access tokens**.
2. UtwÃ³rz **Fine-grained token** z dostÄ™pem do wybranego repozytorium (Contents: Read/Write).
3. Zapisz token â€“ bÄ™dzie uÅ¼yty jako hasÅ‚o.

### 0.3 Klon repozytorium w Cloud Shell

```bash
git clone https://github.com/<owner>/<repo>.git
cd <repo>
```

Podczas klonowania:

* **Username** = TwÃ³j login GitHub
* **Password** = wygenerowany token **PAT**

Upewnij siÄ™, Å¼e w repo jest `.gitignore` ignorujÄ…cy pliki Terraforma, np.:

```gitignore
.terraform/
*.tfstate
*.tfstate.*
```

---

## âš™ï¸ KROK 1 â€“ Odtworzenie AML Workspace z Terraform <a id="k1"></a>

ZakÅ‚adamy, Å¼e z poprzednich Ä‡wiczeÅ„ masz w repo:

```text
terraform/
  terraform-aml-lab/
  terraform-vm-lab/
```

### 1.1 PrzejÅ›cie do katalogu Terraforma dla AML

```bash
cd terraform/terraform-aml-lab
```

### 1.2 Sprawdzenie / ustawienie subskrypcji

```bash
az account show --output table
az account set --subscription "Azure for Students"
```

### 1.3 Inicjalizacja i wdroÅ¼enie

```bash
terraform init
terraform plan
terraform apply -auto-approve
terraform output
```

W outputach powinny byÄ‡ m.in.:

* nazwa resource group, np. `rg-aml-<indeks>`,
* nazwa workspace, np. `amlws-<indeks>`,
* link do AML Studio.

---

## â˜ï¸ KROK 2 â€“ Konfiguracja Azure ML CLI v2 i Compute Cluster <a id="k2"></a>

### 2.1 Instalacja rozszerzenia ML

```bash
az extension add -n ml -y
```

### 2.2 Ustawienie domyÅ›lnych parametrÃ³w CLI

```bash
az configure --defaults group=rg-aml-<indeks> workspace=amlws-<indeks> location=francecentral
```

### 2.3 Utworzenie AML Compute Cluster

```bash
CLUSTER=cpu-cluster-<indeks>

az ml compute create \
  --name $CLUSTER \
  --type amlcompute \
  --size Standard_DS2_v2 \
  --min-instances 0 \
  --max-instances 1 \
  --idle-time-before-scale-down 120
```



---

## ğŸ“ KROK 3 â€“ Struktura katalogu `aml-lab-02` <a id="k3"></a>

Wracamy do gÅ‚Ã³wnego katalogu repozytorium:

```bash
cd ~/<nazwa-twojego-repozytorium>
mkdir -p aml-lab-02/src
cd aml-lab-02
```

Docelowo w `aml-lab-02/` bÄ™dziemy mieli:

```text
aml-lab-02/
â”œâ”€â”€ data_job.yml
â”œâ”€â”€ training_job.yml
â””â”€â”€ src/
    â”œâ”€â”€ data_prep.py
    â””â”€â”€ train.py
```

---

## ğŸ’¾ KROK 4 â€“ Job do generowania danych (data_prep.py + data_job.yml) <a id="k4"></a>

### 4.1 Skrypt `src/data_prep.py`

PrzejdÅº do katalogu `src`:

```bash
cd ~/<nazwa-twojego-repozytorium>/aml-lab-02/src
```

UtwÃ³rz plik `data_prep.py`:

```python
from pathlib import Path

import pandas as pd
from sklearn.datasets import make_classification


def main():
    print("GenerujÄ™ datasetâ€¦")
    X, y = make_classification(
        n_samples=500,
        n_features=10,
        n_informative=4,
        random_state=24,
    )

    df = pd.DataFrame(X, columns=[f"f{i}" for i in range(10)])
    df["label"] = y

    out_dir = Path("outputs")
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "data.csv"

    df.to_csv(out_path, index=False)
    print(f"âœ” Dataset zapisany: {out_path}")


if __name__ == "__main__":
    main()
```

> `outputs/` to domyÅ›lny katalog artefaktÃ³w w AML â€“ wszystko, co tam zapiszemy, bÄ™dzie dostÄ™pne po zakoÅ„czeniu joba.

### 4.2 Definicja joba danych â€“ `data_job.yml`

WrÃ³Ä‡ do katalogu `aml-lab-02`:

```bash
cd ~/<nazwa-twojego-repozytorium>/aml-lab-02
```

UtwÃ³rz plik `data_job.yml`:

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command
display_name: aml02-data-prep-job
experiment_name: aml02-data-prep

code: .
command: python src/data_prep.py

environment: azureml://registries/azureml/environments/sklearn-1.5/versions/34
compute: azureml:cpu-cluster-<indeks>

limits:
  timeout: 3600
```

### 4.3 Uruchomienie joba generujÄ…cego dane

```bash
JOB_DATA=$(az ml job create --file data_job.yml --query name -o tsv)
az ml job stream --name $JOB_DATA
```

Po zakoÅ„czeniu joba w AML Studio (Jobs â†’ `aml02-data-prep`) w zakÅ‚adce *Outputs + logs* powinien byÄ‡ plik `outputs/data.csv`.

---

## ğŸ“¦ KROK 5 â€“ Pobranie danych i rejestracja Data Asset <a id="k5"></a>

### 5.1 Pobierz artefakty joba do Cloud Shell

```bash
az ml job download --name $JOB_DATA --download-path downloaded_data
ls -R downloaded_data
# powinno byÄ‡: downloaded_data/artifacts/outputs/data.csv
```

### 5.2 Rejestracja Data Asset z lokalnego pliku

```bash
az ml data create \
  --name demo-data-<indeks> \
  --path downloaded_data/outputs/data.csv \
  --type uri_file \
  --description "Dataset wygenerowany w AML Lab 02"
```

SprawdÅº:

```bash
az ml data list -o table
```

---

## ğŸ§  KROK 6 â€“ Kod treningowy modelu (`train.py`) <a id="k6"></a>

Teraz napiszemy skrypt, ktÃ³ry:

* przyjmuje Å›cieÅ¼kÄ™ do pliku CSV jako argument `--data`,
* trenuje prosty model logistycznej regresji,
* zapisuje wynik do `outputs/model.joblib` i `outputs/metrics.json`.

PrzejdÅº do `src`:

```bash
cd ~/<nazwa-twojego-repozytorium>/aml-lab-02/src
```

UtwÃ³rz plik `train.py`:

```python
import argparse
import json
from pathlib import Path

import joblib
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--data",
        type=str,
        required=True,
        help="ÅšcieÅ¼ka do pliku CSV z danymi treningowymi",
    )
    return parser.parse_args()


def main():
    args = parse_args()
    data_path = args.data
    print(f"Czytam dane z: {data_path}")

    df = pd.read_csv(data_path)

    X = df.drop("label", axis=1)
    y = df["label"]

    Xtr, Xte, ytr, yte = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    clf = LogisticRegression(max_iter=1000)
    clf.fit(Xtr, ytr)

    acc = accuracy_score(yte, clf.predict(Xte))
    print(f"DokÅ‚adnoÅ›Ä‡ modelu: {acc:.4f}")

    out_dir = Path("outputs")
    out_dir.mkdir(parents=True, exist_ok=True)

    (out_dir / "metrics.json").write_text(
        json.dumps({"accuracy": acc}, indent=2)
    )
    joblib.dump(clf, out_dir / "model.joblib")

    print("âœ” Model i metryki zapisane w katalogu outputs/")


if __name__ == "__main__":
    main()
```



---

## â–¶ï¸ KROK 7 â€“ Training job (`training_job.yml`) <a id="k7"></a>

WrÃ³Ä‡ do `aml-lab-02`:

```bash
cd ~/<nazwa-twojego-repozytorium>/aml-lab-02
```

UtwÃ³rz plik `training_job.yml`:

```yaml
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

display_name: aml02-sklearn-training-job
experiment_name: aml02-training

code: .
command: >
  python src/train.py
  --data ${{inputs.training_data}}

environment: azureml://registries/azureml/environments/sklearn-1.5/versions/34
compute: azureml:cpu-cluster-<indeks>

inputs:
  training_data:
    type: uri_file
    path: azureml:demo-data-<indeks>@latest

limits:
  timeout: 3600
```

Co tu siÄ™ dzieje:

* `inputs.training_data` wskazuje na **Data Asset** `demo-data-<indeks>`,
* AML mapuje asset na lokalnÄ… Å›cieÅ¼kÄ™ w kontenerze i wstrzykuje jÄ… w miejsce `${{inputs.training_data}}`,
* ostatecznie w kontenerze dziaÅ‚a komenda np.:
  `python src/train.py --data /mnt/azureml/.../data.csv`,
* `train.py` Å‚aduje dane z tej Å›cieÅ¼ki i zapisuje wyniki do `outputs/`.

### Uruchomienie training job

```bash
JOB_TRAIN=$(az ml job create --file training_job.yml --query name -o tsv)
az ml job stream --name $JOB_TRAIN
```

Po zakoÅ„czeniu:

* w Azure ML Studio â†’ *Jobs â†’ aml02-training â†’ Run*
  moÅ¼esz sprawdziÄ‡:

  * zakÅ‚adkÄ™ **Metrics** (accuracy),
  * zakÅ‚adkÄ™ **Outputs + logs** (`outputs/model.joblib`, `outputs/metrics.json`).

---

## ğŸ·ï¸ KROK 8 â€“ Rejestracja modelu <a id="k8"></a>

Najpierw pobierz artefakty lokalnie:

```bash
mkdir -p ~/aml-lab-02-results/train_run_download
az ml job download --name $JOB_TRAIN --download-path ~/aml-lab-02-results/train_run_download
ls -R ~/aml-lab-02-results/train_run_download
# oczekiwane: .../artifacts/outputs/model.joblib i metrics.json
```

ZaÅ‚Ã³Å¼my, Å¼e model leÅ¼y w:

```text
~/aml-lab-02-results/train_run_download/artifacts/outputs/
```

Rejestracja modelu:

```bash
MODEL_NAME=sklearn-intro-<indeks>

az ml model create \
  --name $MODEL_NAME \
  --type custom_model \
  --path ~/aml-lab-02-results/train_run_download/artifacts/outputs \
  --description "Model LogisticRegression â€“ AML Lab 02" \
  --tags "lab=aml02 framework=sklearn"
```

SprawdÅº modele:

```bash
az ml model list --name $MODEL_NAME -o table
```

W Azure ML Studio â†’ **Assets â†’ Models** powinieneÅ› zobaczyÄ‡ `sklearn-intro-<indeks>`.

ZrÃ³b screenshot zakÅ‚adki Details dla nowo utworzonego modelu. Dodaj do repozytorium jako dokumentacja

---

## ğŸ§¹ KROK 9 â€“ SprzÄ…tanie zasobÃ³w <a id="k9"></a>

### 9.1 UsuÅ„ compute cluster

```bash
az ml compute delete --name cpu-cluster-<indeks> --yes
```

### 9.2 UsuÅ„ infrastrukturÄ™ AML (Terraform)

```bash
cd ~/<nazwa-twojego-repozytorium>/terraform/terraform-aml-lab
terraform destroy -auto-approve
```



---

## ğŸ“ KROK 10 â€“ Dodanie plikÃ³w do repozytorium <a id="k10"></a>

Wracamy do root repo:

```bash
cd ~/<nazwa-twojego-repozytorium>
```

Struktura powinna wyglÄ…daÄ‡ mniej wiÄ™cej tak:

```text
<repo>/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ terraform-aml-lab/
â”‚   â””â”€â”€ terraform-vm-lab/
â””â”€â”€ aml-lab-02/
    â”œâ”€â”€ model-details.jpg
    â”œâ”€â”€ data_job.yml
    â”œâ”€â”€ training_job.yml
    â””â”€â”€ src/
        â”œâ”€â”€ data_prep.py
        â””â”€â”€ train.py
```

Dodaj i wypchnij zmiany:

```bash
git add aml-lab-02
git commit -m "AML Lab 02 â€“ data asset + training job + model registry"
git push
```

---


